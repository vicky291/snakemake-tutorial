Building DAG of jobs...
Using shell: /bin/bash
Provided cores: 1 (use --cores to define parallelism)
Rules claiming more threads will be scaled down.
Job stats:
job               count    min threads    max threads
--------------  -------  -------------  -------------
bcftools_call         1              1              1
bwa_map               2              1              1
samtools_index        2              1              1
samtools_sort         2              1              1
total                 7              1              1

Select jobs to execute...

[Thu Nov 18 14:10:58 2021]
rule bwa_map:
    input: data/genome.fa, data/samples/A.fastq
    output: mapped_reads/A.bam
    jobid: 2
    wildcards: sample=A
    resources: tmpdir=/var/folders/hr/dvggvx5s4s9fts3zvt6rlh_c0000gn/T

[Thu Nov 18 14:11:00 2021]
Error in rule bwa_map:
    jobid: 2
    output: mapped_reads/A.bam
    shell:
        bwa mem data/genome.fa data/samples/A.fastq | smatools view -Sb - > mapped_reads/A.bam
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)

Removing output files of failed job bwa_map since they might be corrupted:
mapped_reads/A.bam
Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
Complete log: /Users/tangyirui/Work/snakemake-tutorial/.snakemake/log/2021-11-18T141054.827759.snakemake.log
